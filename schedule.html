<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Deep Learning for Computer Vision, Speech, and Language</title>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0-beta/css/materialize.min.css">
<style>
  
</style>    
</head>
<body>
  <nav>
    <div class="nav-wrapper">
      <a href="#" >Columbia University EECS6894</a>
      <ul id="nav-mobile" class="right">
        <li><a href="index.html">Home</a></li>
        <li><a href="schedule.html">Schedule</a></li>
        <li><a href="homework.html">Homework</a></li>
       <li><a href="project.html"> Project</a></li>   
      </ul>
    </div>
  </nav>

<div class="container">

    <h2>Deep Learning for Computer Vision, Speech, and Language</h2>

    <b>Tentative Course Schedule</b><br>

     <table>
        <thead>
          <tr>
              <th>Date</th>
              <th>Lectures</th>
              <th>Other</th>
          </tr>
        </thead>

        <tbody>
          <tr>
            <td>class 1 (09/04)</td>
            <td>Liangliang, <a href="lecture/lecture1_llcao.pdf">Course overview</a></td>
            <td><a href="hw/hw1.html">1st homework</a> released </td>
          </tr>

          <tr>
            <td>class 2 (09/11)</td>
            <td>Xiaodong, Kapil: <a href="lecture/nn_fundamentals_cuix.pdf">Neural Network Fundamentals</a> and <a href="lecture/lecture2_optimization_kapil.pdf">Optimization</a> </td>
            <td></td>
          </tr>
            
          <tr>
            <td>class 3 (09/18)</td>
            <td>Kapil: <a href="lecture/lecture3_representations_kapil.pdf">Language Representation and Recurrent Nets</a></td>
            <td></td>
          </tr>


          <tr>
            <td>class 4 (09/25)</td>
            <td>Xiaodong: <a href="lecture/lecture4_asr1_cuix.pdf">Deep Learning for Automatic Speech Recognition -- Part I</a></td>             
            <td>1st homework due</br>
                <a href="hw/hw2.html">2nd homework</a> released 
            <td>
          </tr>
            
          <tr>
            <td>class 5 (10/02)</td>
            <td>Liangliang: <a href="lecture/lecture5_llcao.pdf">Evolvement of Convolutional Networks</a>. <br>
              Guest lecturer <a href="https://www.microsoft.com/en-us/research/people/leizhang/">Lei Zhang</a>:
               <a href="lecture/lecture5_leizhang_Large-scale face recognition.pdf">Large Scale Face Recongition with MS Celeb 1M</a><br> 
            </td>
            <td></td>
          </tr>
            
          <tr>
            <td>class 6 (10/09)</td>
            <td>Xiaodong: <a href="lecture/lecture6_asr2_cuix.pdf">Deep Learning for Automatic Speech Recognition -- Part II</a></td>
            <td>Student paper presentation<br>
                zx2214,mg3825,yz3170, <a href="http://jmlr.org/proceedings/papers/v32/graves14.pdf">Towards End-to-End Speech Recognition with Recurrent Neural Networks</a><a href="https://docs.google.com/presentation/d/1jcFPnTq7hwwjrKZa2jHFvtCHrmTMGvuhDle1mnADDFQ/edit?usp=sharing">[Slide]</a> <br>
                ss5410,cc4181,ml4025, <a href="https://arxiv.org/pdf/1412.5567v2.pdf">Deep Speech: Scaling up end-to-end speech recognition</a> <a href="https://docs.google.com/presentation/d/1DJeWtVhaKgDXHjDgxxhj6_H402FvTRJyDQK24zY37Q0/edit?usp=sharing">[Slides]</a><br>
            </td>              
          </tr>            

          <tr>
            <td>class 7 (10/16)</td>
            <td>Xiaodong: <a href="lecture/lecture7_asr3_cuix.pdf">Deep Learning for Automatic Speech Recognition -- Part III</a></td>
            <td>Student paper presentation<br>
                zj2242,zq2154,hz2482, <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/dbn4lvcsr-transaslp.pdf">Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition</a><a href="https://docs.google.com/presentation/d/1Jz6Shp5VnakyQkylsKUDsQA0zbam-HOTsTAifl7q45A/edit#slide=id.p11">[Slides]</a> <br>
                ac4218,bj2376,ys3031, <a href="https://arxiv.org/pdf/1610.09975.pdf">Acoustic-to-Word LSTM Model for Large Vocabulary Speech Recognition</a> <a href="https://docs.google.com/presentation/d/1jA0_VcqCmEdtgTB75c5E5xoOSLvCPecMx4WHMSF41_U/edit#slide=id.g44fe6c14e1_2_0">[Slides]</a><br>
                jl4924,cz2465,cy2468, <a href="https://arxiv.org/pdf/1508.01211.pdf">Listen, Attend and Spell</a> <a href="https://docs.google.com/presentation/d/1UMO41Kwu_O-5VYY4Irkjp30DZOLOybxq4P1BcRGtWgs/edit?usp=sharing">[Slides]</a><br> 
                hl3100,ls3439,jl4930, <a href="https://arxiv.org/pdf/1610.05256.pdf">Toward Human Parity in Conversational Speech Recognition</a> and <a href="https://arxiv.org/pdf/1703.02136.pdf">English Conversational Telephone Speech Recognition by Humans and Machines</a><a href="https://docs.google.com/presentation/d/1NmpVWClHmvqN7VTW2-SfyhaY52IFveS8_Oy0BuP5BzY/edit?usp=sharing">[Slides]</a> <br>
            </td>          
          </tr> 
            
          <tr>
            <td>class 8 (10/23)</td>
            <td>Kapil: Encoder-decoder architectures</td>
            <td>3rd homework<br><br>
                Student paper presentation<br>
                wc2608,jh3853, <a href="https://arxiv.org/abs/1609.08144">Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</a> (also mention <a href="https://arxiv.org/abs/1611.04558">Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation</a>) <br>
                jw3535,yg2520,cz2458, <a href="https://arxiv.org/abs/1511.06349">Generating Sentences from a Continuous Space</a> <br>
                cb3331,mz2649,zc2393, <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-training</a> (also mention <a href="https://arxiv.org/abs/1801.06146">Universal Language Model Fine-tuning for Text Classification</a>) <br>
              </td>
          </tr>
          

          <tr>
            <td>class 9 (10/30)</td>
            <td>Liangliang: [Vision] Advanced Vision Topics</td>
            <td>Student paper presentation<br>
                yl3747,yw2924,yh2950, <a href="https://arxiv.org/abs/1608.06993">Densely Connected Convolutional Networks</a> <br>
                lz2576,St3186, <a href="https://arxiv.org/abs/1706.02677">Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</a> <br>
                hc3040,jak2294, <a href="https://openreview.net/pdf?id=HJWLfGWRb">Matrix capsules with EM routing</a> <br>
                zh2318,xw2501,rcj2118, <a href="https://www.researchgate.net/profile/Zhengming_Ding2/publication/325632758_One-Shot_Face_Recognition_via_Generative_Learning/links/5ba12ce392851ca9ed14a4d5/One-Shot-Face-Recognition-via-Generative-Learning.pdf?origin=publication_detail">One-Shot Face Recognition via Generative Learning</a><br>
            </td>
          </tr>  
            
          <tr>
            <td>class 10 (11/06)</td>
            <td>University Holiday (no class)</td>
            <td></td>
          </tr>    
            
          <tr>
            <td>class 11 (11/13)</td>
            <td>Kapil: Reinforcement learning </td>
            <td>4th homework<br><br>
                Student paper presentation<br>
                xl2680,yg2523,js5334, <a href="https://www.nature.com/articles/nature24270.pdf">Mastering the game of Go without human knowledge</a> <br>
                hs2991,sw3196,ty2362, <a href="https://arxiv.org/abs/1601.01705">Learning to Compose Neural Networks for Question Answering</a> and <a href="https://arxiv.org/abs/1704.05526"> Learning to Reason: End-to-End Module Networks for Visual Question Answering</a><br>
                jz2883,jc4805,hd2377, <a href="https://arxiv.org/abs/1611.01578">Neural Architecture Search with Reinforcement Learning</a> <br>
              </td>
         </tr>      
            
          <tr>
            <td>class 12 (11/20)</td>
            <td>[Vision]
              
              Guest lecturer <a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-nccodell">
                Noel Codella</a>: Medical image understanding
            </td>

            <td>
              Student paper presentation<br>
              xz2631,yz3169,xz2663, <a href="https://www.nature.com/articles/nature21056">Dermatologist-level classification of skin cancer with deep neural networks</a> <br>
              xl2699,hx2224,hz2489, <a href="https://arxiv.org/pdf/1707.07328.pdf">Adversarial examples for evaluating reading comprehension systems</a><br>
              hh2699,th2713,jm4743, <a href="http://abedavis.com/visualbeat/">Visual Rhythm and Beat</a>
            </td>

          </tr>   
            
          <tr>
            <td>class 13 (11/27)</td>
            <td>
            Guest lecturer <a href="https://www.linkedin.com/in/honghuis/">Honghui Shi</a>: Object detection<br>  
            Guest lecturer <a href="http://andrewkae.com/">Andrew Kae</a>: Generative Adversarial Networks </td>
            <td>
              

            </td>
          </tr>  
            
          <tr>
            <td>class 14 (12/04)</td>
            <td>No class </td>
            <td></td>
          </tr>    
         
          <tr>
            <td>class 15 (12/11)</td>
            <td>Final presentations and demos </td>
            <td></td>
          </tr>              
            
        </tbody>
    </table>     
    
</div>
</body>
</html>
